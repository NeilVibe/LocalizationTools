# GlossarySniffer Roadmap

**Created**: 2025-11-24
**Status**: In Development
**Reference Script**: QuickSearch0818.py (Aho-Corasick glossary extraction)

---

## üéØ Purpose

**GlossarySniffer** extracts glossary terms from XML files and searches for them in Excel text lines, outputting which glossary terms appear in each line.

### Use Case
- Analyze translation lines to identify glossary terms automatically
- Build glossary from XML `StrOrigin` attributes with smart filtering
- Fast multi-pattern matching using Aho-Corasick algorithm
- Output Excel with original lines + glossary terms found

---

## üìã Input/Output

### Input 1: XML Glossary Source
**Format**: XML file with `StrOrigin` attributes
```xml
<Texts>
  <Text>
    <LocStr StrOrigin="Kliff" Str="Kliff"/>
    <LocStr StrOrigin="Calphade" Str="Calphade"/>
    <LocStr StrOrigin="Duke Elenor" Str="Duke Elenor"/>
    <LocStr StrOrigin="Lands of Gogogugu" Str="Lands of Gogogugu"/>
  </Text>
</Texts>
```

### Input 2: Lines to Analyze
**Format**: Excel file (`.xlsx`) with lines to check
```
| Line                                              |
|---------------------------------------------------|
| Kliff went to Calphade to talk to his friends    |
| I am Duke Elenor, and I rule over the Lands of Gogogugu |
```

### Output: Analysis Result
**Format**: Excel file with original lines + glossary terms found
```
| Original Line                                              | Glossary Terms Found      |
|------------------------------------------------------------|---------------------------|
| Kliff went to Calphade to talk to his friends             | Kliff, Calphade           |
| I am Duke Elenor, and I rule over the Lands of Gogogugu   | Duke Elenor, Lands of Gogogugu |
```

---

## üîß Glossary Building Logic - HARDCODED RULES

### ‚öôÔ∏è All Rules Hardcoded (No User Input Needed!)

**Based on QuickSearch0818.py glossary_filter() lines 2113-2149**

### 5 HARDCODED FILTERING RULES:

**Rule 1: Length Threshold**
```python
DEFAULT_LENGTH_THRESHOLD = 15  # Korean names/terms are usually short
```
- ‚úÖ KEEP: Terms < 15 characters
- ‚ùå SKIP: Anything >= 15 characters (too long, likely a phrase/sentence)

**Rule 2: Minimum Occurrence**
```python
MIN_OCCURRENCE = 2  # Must appear at least 2 times
```
- ‚úÖ KEEP: Terms that appear 2+ times in XML
- ‚ùå SKIP: One-off terms (likely typos or descriptions, not real glossary)

**Rule 3: No Punctuation Endings**
```python
FILTER_SENTENCES = True
Pattern: r'[.?!]\s*$'  # Ends with .?!
```
- ‚úÖ KEEP: "Kliff", "Duke Elenor"
- ‚ùå SKIP: "Welcome.", "How are you?", "Hello!"

**Rule 4: No Punctuation Inside**
```python
FILTER_PUNCTUATION = True
Checks: string.punctuation (except spaces/hyphens) + special ellipsis ‚Ä¶
```
- ‚úÖ KEEP: "Duke Elenor" (space ok), "Black-Desert" (hyphen ok)
- ‚ùå SKIP: "Hello, world", "Wait‚Äîwhat", "Well..."

**Rule 5: Non-Empty Only**
- ‚úÖ KEEP: Any non-empty string
- ‚ùå SKIP: Empty strings, None values

### Two-Pass Filtering (Like QuickSearch0818)
```python
# Pass 1: Basic filtering + count occurrences
for term in all_terms:
    if passes_basic_filters(term):
        count_map[term] += 1

# Pass 2: Apply min_occurrence filter
glossary = [term for term, count in count_map.items() if count >= MIN_OCCURRENCE]

# Sort by frequency (most common first)
glossary.sort(key=count, reverse=True)
```

### Example Filtering
```
INPUT: 1000 StrOrigin entries from XML

‚úÖ KEEP (111 terms after filtering):
- "ÌÅ¥Î¶¨ÌîÑ" (4 chars, appears 5 times)
- "ÏπºÌååÎç∞" (4 chars, appears 3 times)
- "ÏóòÎ†àÎÖ∏Ïñ¥ Í≥µÏûë" (8 chars, appears 2 times)
- "Í≥†Í≥†Íµ¨Íµ¨ ÎïÖ" (7 chars, appears 2 times)
- "Í≤ÄÏùÄÏÇ¨Îßâ" (4 chars, appears 10 times)

‚ùå SKIP:
- "ÌÅ¥Î¶¨ÌîÑÍ∞Ä ÎèÑÏãúÏóê Í∞îÎã§." (ends with ., sentence)
- "ÏïàÎÖïÌïòÏÑ∏Ïöî, Ïó¨ÌñâÏûêÎãò!" (contains comma and !, punctuation)
- "Ïù¥Í≤ÉÏùÄ Îß§Ïö∞ Í∏¥ ÏÑ§Î™ÖÏûÖÎãàÎã§" (16 chars, too long)
- "ÏûÑÏãúÌï≠Î™©" (1 occurrence only, not recurring glossary)
- "..." (only punctuation)
```

### Word Boundary Matching
```python
WORD_BOUNDARIES = True  # Only match complete words
```
- ‚úÖ MATCH: "Duke" in "The Duke arrived"
- ‚ùå SKIP: "Duke" inside "Archduke" (not at word boundary)

---

## ‚ö° Search Algorithm: Aho-Corasick + Word Boundaries

### Why Aho-Corasick?
- **Fast multi-pattern matching**: Search for ALL glossary terms in single pass
- **Efficient**: O(n + m + z) where n=text length, m=total pattern length, z=matches
- **Perfect for glossary**: Can find overlapping patterns
- **Proven in QuickSearch0818**: Already successfully used in production

### Implementation Steps (Enhanced)
1. **Build Automaton**: Add all glossary terms to Aho-Corasick automaton
2. **Make Automaton**: Finalize state machine for fast searching
3. **Scan Each Line**: Use automaton to find all glossary term candidates
4. **Word Boundary Check**: Validate each match is at word boundaries (not inside other words)
5. **Aggregate Results**: Collect all valid unique terms found per line

### Word Boundary Logic (NEW!)
```python
# For each Aho-Corasick match, check:
start_pos = match_end - len(term) + 1

# Character before match (if exists)
if start_pos > 0:
    char_before = line[start_pos - 1]
    if char_before.isalnum():
        skip  # Inside a word!

# Character after match (if exists)
if match_end + 1 < len(line):
    char_after = line[match_end + 1]
    if char_after.isalnum():
        skip  # Inside a word!
```

### Example Search with Word Boundaries
```python
# Glossary terms: ["ÌÅ¥Î¶¨ÌîÑ", "Í≥µÏûë", "ÏóòÎ†àÎÖ∏Ïñ¥ Í≥µÏûë"]
# Line: "ÌÅ¥Î¶¨ÌîÑÍ∞Ä ÏóòÎ†àÎÖ∏Ïñ¥ Í≥µÏûëÏùÑ ÎßåÎÇ¨Îã§"

# Aho-Corasick finds: ["ÌÅ¥Î¶¨ÌîÑ", "Í≥µÏûë", "ÏóòÎ†àÎÖ∏Ïñ¥ Í≥µÏûë"]
# Word boundary check:
#   - "ÌÅ¥Î¶¨ÌîÑ" ‚úÖ (Í∞Ä is not alnum in this context)
#   - "Í≥µÏûë" inside "ÏóòÎ†àÎÖ∏Ïñ¥ Í≥µÏûë" ‚ùå (prefer longest)
#   - "ÏóòÎ†àÎÖ∏Ïñ¥ Í≥µÏûë" ‚úÖ (ÏùÑ is not alnum)

# Final output: "ÌÅ¥Î¶¨ÌîÑ, ÏóòÎ†àÎÖ∏Ïñ¥ Í≥µÏûë"
```

### Korean Language Considerations
- Korean doesn't have case sensitivity (no uppercase/lowercase)
- Word boundaries work with particles (Í∞Ä, ÏùÑ, Îäî, etc.)
- Multi-word Korean terms work fine ("ÏóòÎ†àÎÖ∏Ïñ¥ Í≥µÏûë")

---

## üîÑ Development Plan

### Phase 1: XML Glossary Extraction ‚úÖ (Target: Complete)
- [ ] Parse XML files using `lxml` or `xml.etree.ElementTree`
- [ ] Extract all `StrOrigin` attributes
- [ ] Apply length threshold filter (default: 30 chars)
- [ ] Remove entries with punctuation
- [ ] Remove full sentences
- [ ] Deduplicate terms
- [ ] Save glossary to internal list

**Reference**: QuickSearch0818.py lines 2113-2149 (glossary_filter function)

### Phase 2: Excel Input Handling ‚úÖ (Target: Complete)
- [ ] Read Excel file with `openpyxl`
- [ ] Extract lines from first column (or user-specified column)
- [ ] Store lines in list for processing

**Reference**: Standard openpyxl patterns from XLSTransfer, QuickSearch

### Phase 3: Aho-Corasick Search Implementation ‚úÖ (Target: Complete)
- [ ] Import `ahocorasick` library
- [ ] Build automaton with all glossary terms
- [ ] For each Excel line:
  - [ ] Run Aho-Corasick search
  - [ ] Collect all matched glossary terms
  - [ ] Handle overlapping matches (e.g., "Duke" vs "Duke Elenor")
- [ ] Prefer longest matches for overlapping terms

**Reference**: QuickSearch0818.py lines 2211-2259 (Aho-Corasick implementation)

### Phase 4: Excel Output Generation ‚úÖ (Target: Complete)
- [ ] Create new Excel workbook
- [ ] Column 1: Original lines
- [ ] Column 2: Glossary terms found (comma-separated)
- [ ] Format: Clean, readable
- [ ] Save to output file

**Reference**: openpyxl workbook creation patterns

### Phase 5: GUI & File Pickers ‚úÖ (Target: Complete)
- [ ] Tkinter file picker for XML glossary source
- [ ] Tkinter file picker for Excel input lines
- [ ] Tkinter save dialog for Excel output
- [ ] Progress messages
- [ ] Error handling

**Reference**: Standard Tkinter patterns from all NewScripts

### Phase 6: Advanced Features (Optional)
- [ ] Configurable length threshold (GUI input)
- [ ] Option to include/exclude punctuation
- [ ] Case-sensitive vs case-insensitive matching
- [ ] Multiple XML source files
- [ ] Column selection for Excel input
- [ ] Statistics (total lines, terms found, coverage %)

---

## üì¶ Dependencies

```bash
pip install openpyxl lxml pyahocorasick
```

### Libraries Used
- **openpyxl**: Excel file handling (read/write .xlsx)
- **lxml**: Fast XML parsing (preferred) or xml.etree.ElementTree (fallback)
- **pyahocorasick**: Aho-Corasick algorithm for fast multi-pattern matching
- **tkinter**: GUI file pickers (built-in Python)
- **re**: Regular expressions for text cleaning/filtering
- **string**: Punctuation detection for filtering

### Why These Libraries?
- **Aho-Corasick**: 10-100x faster than regex for multi-pattern matching
- **lxml**: Faster than ElementTree for large XML files
- **openpyxl**: Standard Excel library, reliable for .xlsx
- All proven in QuickSearch0818 production use

---

## üé® Script Structure

### File Name
`glossary_sniffer_1124.py`

### Main Functions
```python
def extract_glossary_from_xml(xml_path, length_threshold=30):
    """
    Extract glossary terms from XML StrOrigin attributes
    Returns: list of glossary terms
    """

def filter_glossary_terms(terms, length_threshold):
    """
    Filter out non-glossary entries (punctuation, long phrases, etc.)
    Returns: filtered list of terms
    """

def build_ahocorasick_automaton(glossary_terms):
    """
    Build Aho-Corasick automaton from glossary terms
    Returns: automaton object
    """

def search_line_for_glossary(line, automaton):
    """
    Search a single line for glossary terms using Aho-Corasick
    Returns: list of matched terms
    """

def process_excel_lines(excel_path, automaton):
    """
    Read Excel, search each line, return results
    Returns: list of (original_line, glossary_terms_found) tuples
    """

def write_results_to_excel(results, output_path):
    """
    Write results to Excel with 2 columns:
    - Column 1: Original Line
    - Column 2: Glossary Terms Found (comma-separated)
    """

def main():
    """
    Main execution:
    1. Pick XML glossary source
    2. Build glossary
    3. Pick Excel input file
    4. Search for glossary terms
    5. Save results to Excel
    """
```

---

## ‚úÖ Testing Plan

### Test Case 1: Basic Glossary Extraction
**Input XML**:
```xml
<LocStr StrOrigin="Kliff" Str="Kliff"/>
<LocStr StrOrigin="Calphade" Str="Calphade"/>
<LocStr StrOrigin="This is a long sentence that should be filtered." Str="..."/>
<LocStr StrOrigin="Hello, world!" Str="..."/>
```

**Expected Glossary**: `["Kliff", "Calphade"]`

### Test Case 2: Multi-Word Terms
**Input XML**:
```xml
<LocStr StrOrigin="Duke Elenor" Str="Duke Elenor"/>
<LocStr StrOrigin="Lands of Gogogugu" Str="Lands of Gogogugu"/>
```

**Expected Glossary**: `["Duke Elenor", "Lands of Gogogugu"]`

### Test Case 3: Line Search
**Glossary**: `["Kliff", "Calphade", "Duke Elenor"]`
**Excel Line**: `"Kliff went to Calphade to meet Duke Elenor"`
**Expected Match**: `"Kliff, Calphade, Duke Elenor"`

### Test Case 4: Overlapping Terms
**Glossary**: `["Duke", "Duke Elenor"]`
**Excel Line**: `"I am Duke Elenor"`
**Expected Match**: `"Duke Elenor"` (prefer longest match)

### Test Case 5: No Matches
**Glossary**: `["Kliff", "Calphade"]`
**Excel Line**: `"Hello world"`
**Expected Match**: `""` (empty)

---

## üöÄ Performance Goals

- **Glossary Building**: <5 seconds for 10,000 XML entries
- **Aho-Corasick Automaton**: <1 second for 5,000 terms
- **Line Searching**: <10 seconds for 10,000 lines with 5,000-term glossary
- **Excel Output**: <5 seconds for 10,000 rows

**Total**: <30 seconds for typical use case

---

## üìä Success Criteria

‚úÖ **Functional**:
- Correctly extracts glossary from XML StrOrigin
- **5 HARDCODED RULES** applied automatically (no user config needed):
  1. Length < 15 chars ‚úÖ
  2. Min 2 occurrences ‚úÖ
  3. No punctuation endings ‚úÖ
  4. No punctuation inside (except space/hyphen) ‚úÖ
  5. Non-empty only ‚úÖ
- **Word boundaries** enforced (no matching inside other words) ‚úÖ
- Finds single-word Korean terms ("ÌÅ¥Î¶¨ÌîÑ") ‚úÖ
- Finds multi-word Korean expressions ("ÏóòÎ†àÎÖ∏Ïñ¥ Í≥µÏûë") ‚úÖ
- Handles overlapping matches correctly (prefers longest) ‚úÖ
- Outputs clean Excel results ‚úÖ

‚úÖ **Performance**:
- Fast enough for 10,000+ lines
- Uses Aho-Corasick for O(n+m+z) efficiency
- Two-pass filtering (like QuickSearch0818)

‚úÖ **User Experience**:
- Simple file picker GUI (no configuration needed!)
- Clear progress messages
- Helpful error messages
- Clean Excel output format
- Shows sample glossary terms after extraction

‚úÖ **Code Quality**:
- Clean, commented code
- Hardcoded rules well-documented
- Error handling
- Follows NewScripts patterns
- Based on proven QuickSearch0818 logic (lines 2113-2259)

---

## üîó References

### Pattern Source
**QuickSearch0818.py** (`RessourcesForCodingTheProject/SECONDARY PYTHON SCRIPTS/`)
- Lines 2113-2149: `glossary_filter()` function (filtering logic)
- Lines 2211-2259: Aho-Corasick automaton building and searching
- Line 24: `import ahocorasick`
- Line 890, 1775, 1803, 1879: `StrOrigin` extraction patterns

### Key Patterns Reused
1. **XML Parsing**: `tree.xpath('//LocStr')` with `locstr.get('StrOrigin', '')`
2. **Glossary Filtering**: Length threshold, punctuation removal, sentence detection
3. **Aho-Corasick**: Build automaton ‚Üí make_automaton() ‚Üí scan text for matches
4. **Excel I/O**: openpyxl patterns from multiple scripts

---

## üìù Notes

- **Keep it standalone**: Single .py file, minimal dependencies
- **Speed matters**: Use Aho-Corasick for fast searching (proven in QuickSearch0818)
- **Smart filtering**: Don't include everything as glossary - filter intelligently
- **Multi-word support**: Must handle "Duke Elenor", "Lands of Gogogugu", etc.
- **User-friendly**: File pickers, progress messages, clear output

---

**Next Step**: Begin Phase 1 (XML Glossary Extraction) üöÄ

---

*Last Updated: 2025-11-24*
*Status: Ready to build!*
